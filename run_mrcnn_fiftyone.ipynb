{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 23:33:28.573982: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.5.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Import Mask RCNN\n",
    "from detector.mrcnn import visualize\n",
    "import detector.mrcnn.model as modellib\n",
    "from detector.mrcnn import utils\n",
    "\n",
    "import lego\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_URL = 'https://api.github.com/repos/LilDataMonster/Lego-CNN/releases/latest'\n",
    "response = json.loads(requests.get(REPO_URL).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                     | 0.00/262M [00:00<?, ?iB/s]\n"
     ]
    }
   ],
   "source": [
    "# LEGO_WEIGHTS_URL = response['assets'][0]['browser_download_url']\n",
    "LEGO_WEIGHTS_URL = \"https://github.com/LilDataMonster/Lego-CNN/releases/download/v0.0.3/mask_rcnn_lego_0200.h5\"\n",
    "LEGO_WEIGHTS_NAME = os.path.basename(LEGO_WEIGHTS_URL)\n",
    "\n",
    "LEGO_WEIGHTS_PATH = Path(os.path.join(\"logs\", \"weights\", LEGO_WEIGHTS_NAME))\n",
    "\n",
    "weights_response = requests.get(LEGO_WEIGHTS_URL, stream=True)\n",
    "total_size_in_bytes= int(weights_response.headers.get('content-length', 0))\n",
    "progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
    "if not LEGO_WEIGHTS_PATH.exists():\n",
    "    # Streaming, so we can iterate over the response.\n",
    "    block_size = 1024 #1 Kibibyte\n",
    "    with open(LEGO_WEIGHTS_NAME, 'wb') as file:\n",
    "        for data in weights_response.iter_content(block_size):\n",
    "            progress_bar.update(len(data))\n",
    "            file.write(data)\n",
    "\n",
    "    if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
    "        print(\"ERROR downloading pretrained weights\")\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(lego.LegoConfig().__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 23:33:39.858400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-02-21 23:33:39.895531: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-02-21 23:33:39.895569: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: TRLPanda\n",
      "2022-02-21 23:33:39.895575: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: TRLPanda\n",
      "2022-02-21 23:33:39.896017: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.82.0\n",
      "2022-02-21 23:33:39.896048: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.82.0\n",
      "2022-02-21 23:33:39.896053: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.82.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights  logs/weights/mask_rcnn_lego_0200.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 23:33:41.158417: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-21 23:33:41.558207: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3493010000 Hz\n"
     ]
    }
   ],
   "source": [
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=\"\", config=config)\n",
    "print(\"Loading weights \", LEGO_WEIGHTS_PATH)\n",
    "model.load_weights(LEGO_WEIGHTS_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup test dataset\n",
    "name = 'white_background_test'\n",
    "\n",
    "if name not in fo.list_datasets():\n",
    "    # The directory containing the dataset to import\n",
    "    dataset_dir = os.path.join('dataset', 'test')\n",
    "    data_path = os.path.join('dataset', 'test')\n",
    "    labels_path = os.path.join('dataset', 'test', 'coco_annotations.json')\n",
    "\n",
    "    # The type of the dataset being imported\n",
    "    dataset_type = fo.types.COCODetectionDataset  # for example\n",
    "\n",
    "    dataset = fo.Dataset.from_dir(\n",
    "        # dataset_dir=dataset_dir,\n",
    "        dataset_type=dataset_type,\n",
    "        data_path=data_path,\n",
    "        labels_path=labels_path,\n",
    "        name=name,\n",
    "    )\n",
    "    dataset.persistent = True\n",
    "    \n",
    "else:\n",
    "    dataset = fo.load_dataset('white_background_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0% ||----------------|   0/500 [124.7ms elapsed, ? remaining, ? samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py:2424: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
      "2022-02-21 23:33:45.444987: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -308 } dim { size: -309 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -19 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -19 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } tensor_content: \"\\007\\000\\000\\000\\007\\000\\000\\000\" } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"248\" frequency: 3493 num_cores: 32 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.99\" } l1_cache_size: 32768 l2_cache_size: 524288 l3_cache_size: 33554432 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -19 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-02-21 23:33:45.445087: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -298 } dim { size: -299 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -22 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -22 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } tensor_content: \"\\007\\000\\000\\000\\007\\000\\000\\000\" } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"248\" frequency: 3493 num_cores: 32 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.99\" } l1_cache_size: 32768 l2_cache_size: 524288 l3_cache_size: 33554432 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -22 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-02-21 23:33:45.445163: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -286 } dim { size: -287 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -24 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } tensor_content: \"\\007\\000\\000\\000\\007\\000\\000\\000\" } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"248\" frequency: 3493 num_cores: 32 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.99\" } l1_cache_size: 32768 l2_cache_size: 524288 l3_cache_size: 33554432 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-02-21 23:33:45.445261: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -272 } dim { size: -273 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -26 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -26 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } tensor_content: \"\\007\\000\\000\\000\\007\\000\\000\\000\" } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"248\" frequency: 3493 num_cores: 32 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.99\" } l1_cache_size: 32768 l2_cache_size: 524288 l3_cache_size: 33554432 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -26 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2022-02-21 23:33:45.448381: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -308 } dim { size: -309 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -34 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -34 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } tensor_content: \"\\016\\000\\000\\000\\016\\000\\000\\000\" } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"248\" frequency: 3493 num_cores: 32 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.99\" } l1_cache_size: 32768 l2_cache_size: 524288 l3_cache_size: 33554432 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -34 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-02-21 23:33:45.448492: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -298 } dim { size: -299 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -36 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } tensor_content: \"\\016\\000\\000\\000\\016\\000\\000\\000\" } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"248\" frequency: 3493 num_cores: 32 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.99\" } l1_cache_size: 32768 l2_cache_size: 524288 l3_cache_size: 33554432 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-02-21 23:33:45.448595: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -286 } dim { size: -287 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -38 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -38 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } tensor_content: \"\\016\\000\\000\\000\\016\\000\\000\\000\" } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"248\" frequency: 3493 num_cores: 32 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.99\" } l1_cache_size: 32768 l2_cache_size: 524288 l3_cache_size: 33554432 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -38 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2022-02-21 23:33:45.448721: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -272 } dim { size: -273 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -40 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -40 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } tensor_content: \"\\016\\000\\000\\000\\016\\000\\000\\000\" } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"248\" frequency: 3493 num_cores: 32 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.99\" } l1_cache_size: 32768 l2_cache_size: 524288 l3_cache_size: 33554432 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -40 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████| 500/500 [18.0m elapsed, 0s remaining, 0.5 samples/s]    \n",
      "Finished adding predictions\n"
     ]
    }
   ],
   "source": [
    "# Choose a random subset of 100 samples to add predictions to\n",
    "# predictions_view = dataset.take(2500, seed=51)\n",
    "predictions_view = dataset.take(500, seed=51)\n",
    "\n",
    "# Add predictions to samples\n",
    "with fo.ProgressBar() as pb:\n",
    "    class_names = ['BG', '2431', '3003', '3005', '3010', '3020', '3021', '3022', '3023', '3024', '3069', '3070', '3176', '3622', '3700', '3710', '3958', '4150', '4274', '6141', '11211', '11476', '11477', '15068', '15573', '22885', '24201', '24246', '25269', '29119', '29120', '33909', '35480', '36840', '47458', '47905', '85984', '87079', '87087', '87580', '93273', '98138', '99206']\n",
    "    for sample in pb(predictions_view):\n",
    "        # Load image\n",
    "        image = tf.keras.preprocessing.image.load_img(sample.filepath)\n",
    "        frame = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        \n",
    "        # Perform inference\n",
    "        results = model.detect([frame], verbose=0)[0]\n",
    "        labels = results['class_ids']\n",
    "        scores = results['scores']\n",
    "        boxes = results['rois']\n",
    "        h, w = np.shape(frame)[:2]\n",
    "        \n",
    "        # print(np.shape(frame)[:2])\n",
    "        # Convert detections to FiftyOne format\n",
    "        detections = []\n",
    "        for label, score, box in zip(labels, scores, boxes):\n",
    "            # Convert to [top-left-x, top-left-y, width, height]\n",
    "            # in relative coordinates in [0, 1] x [0, 1]\n",
    "            # x1, y1, x2, y2 = box\n",
    "            y1, x1, y2, x2 = box\n",
    "            rel_box = [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h]\n",
    "\n",
    "            detections.append(\n",
    "                fo.Detection(\n",
    "                    label=class_names[label],\n",
    "                    bounding_box=rel_box,\n",
    "                    confidence=score\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Save predictions to dataset\n",
    "        sample['Mask-RCNN'] = fo.Detections(detections=detections)\n",
    "        sample.save()\n",
    "\n",
    "print(\"Finished adding predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "# Only contains detections with confidence >= 0.75\n",
    "high_conf_view = predictions_view.filter_labels('Mask-RCNN', F('confidence') > 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |█████████████████| 500/500 [33.4s elapsed, 0s remaining, 15.3 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |█████████████████| 500/500 [36.5s elapsed, 0s remaining, 15.4 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions in the `faster_rcnn` field of our `high_conf_view`\n",
    "# with respect to the objects in the `ground_truth` field\n",
    "results = high_conf_view.evaluate_detections(\n",
    "    'Mask-RCNN',\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    "    use_boxes=True,\n",
    "    classwise=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "counts = dataset.count_values(\"ground_truth.detections.label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_all = list(counts.keys())\n",
    "results.print_report(classes=classes_all)\n",
    "\n",
    "print(f'mAP: {results.mAP()}')\n",
    "\n",
    "# Print some statistics about the total TP/FP/FN counts\n",
    "print(\"TP: %d\" % dataset.sum(\"eval_tp\"))\n",
    "print(\"FP: %d\" % dataset.sum(\"eval_fp\"))\n",
    "print(\"FN: %d\" % dataset.sum(\"eval_fn\"))\n",
    "\n",
    "plot = results.plot_pr_curves(classes=classes_all)\n",
    "plot.show(width=1980, height=1080)\n",
    "\n",
    "# Generate a confusion matrix for the specified classes\n",
    "plot = results.plot_confusion_matrix(classes=classes_all)\n",
    "plot.show(width=1980, height=1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = results.confusion_matrix(classes=classes_all)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes_all)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(32,32))\n",
    "disp.plot(ax=ax)\n",
    "fig.savefig('confusion_matrix.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_metrics_df = pd.DataFrame([results.metrics()])\n",
    "classification_metrics_df.to_csv('classification_metrics.csv')\n",
    "display(classification_metrics_df)\n",
    "\n",
    "classification_report_df = pd.DataFrame(results.report(classes_all)).transpose()\n",
    "classification_report_df.to_csv('classification_report.csv')\n",
    "display(classification_report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.write_json('/tf/outputs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(predictions_view, auto=False)\n",
    "session.open_tab()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
