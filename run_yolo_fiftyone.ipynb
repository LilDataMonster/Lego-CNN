{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, glob\n",
    "from functools import partial\n",
    "\n",
    "import ffmpeg\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "from fiftyone import ViewField as F\n",
    "from fiftyone.utils import yolo\n",
    "import fiftyone.utils.annotations as foua\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2500/2500 [45.3s elapsed, 0s remaining, 52.7 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# setup test dataset\n",
    "name = 'white_background_test'\n",
    "\n",
    "if name not in fo.list_datasets():\n",
    "    # The directory containing the dataset to import\n",
    "    dataset_dir = os.path.join('dataset', 'test')\n",
    "    data_path = os.path.join('dataset', 'test')\n",
    "    labels_path = os.path.join('dataset', 'test', 'coco_annotations.json')\n",
    "\n",
    "    # The type of the dataset being imported\n",
    "    dataset_type = fo.types.COCODetectionDataset  # for example\n",
    "\n",
    "    dataset = fo.Dataset.from_dir(\n",
    "        # dataset_dir=dataset_dir,\n",
    "        dataset_type=dataset_type,\n",
    "        data_path=data_path,\n",
    "        labels_path=labels_path,\n",
    "        name=name,\n",
    "    )\n",
    "    dataset.persistent = True\n",
    "    \n",
    "else:\n",
    "    dataset = fo.load_dataset('white_background_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    }
   ],
   "source": [
    "# visualize dataset in GUI\n",
    "session = fo.launch_app(port=5151, auto=False)#, remote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m requests>=2.23.0 not found and is required by YOLOv5, attempting auto-update...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests>=2.23.0\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63.1/63.1 KB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.23.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.23.0) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.23.0) (1.25.8)\n",
      "Installing collected packages: requests\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "Successfully installed requests-2.27.1\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /root/.cache/torch/hub/ultralytics_yolov5_master/requirements.txt\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "YOLOv5 üöÄ 2022-2-22 torch 1.10.2+cu102 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11019MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 290 layers, 21018615 parameters, 0 gradients, 48.5 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "yolov5_model = torch.hub.load('ultralytics/yolov5', 'custom', path=os.path.join(\"logs\", \"weights\", \"exp12\", \"weights\", \"best.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_detections = lambda row: fo.Detection(\n",
    "                        label=row['name'],\n",
    "                        bounding_box=[row['xcenter'] - row['width']/2, row['ycenter'] - row['height']/2,\n",
    "                                      row['width'], row['height']],\n",
    "                        confidence=row['confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34305ea449634d839e1bf0db13d68167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished adding predictions\n"
     ]
    }
   ],
   "source": [
    "# Choose a random subset of 100 samples to add predictions to\n",
    "predictions_view = dataset.take(2500, seed=51)\n",
    "\n",
    "for sample in tqdm(predictions_view):\n",
    "    # Load image\n",
    "    image = Image.open(sample.filepath)\n",
    "    results = yolov5_model(image)\n",
    "    results_df = results.pandas().xywhn[0]\n",
    "    \n",
    "    detections = results_df.apply(create_detections, axis=1)\n",
    "    sample['YOLOv5'] = fo.Detections(detections=detections.values.tolist())\n",
    "    sample.save()\n",
    "\n",
    "print(\"Finished adding predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = predictions_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing YOLOv5\n",
      "Evaluating detections...\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2500/2500 [3.3m elapsed, 0s remaining, 13.2 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2500/2500 [3.2m elapsed, 0s remaining, 12.3 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "classes = ['2431', '3003', '3005', '3010', '3020', '3021', '3022',\n",
    "           '3023', '3024', '3069', '3070', '3176', '3622', '3700',\n",
    "           '3710', '3958', '4150', '4274', '6141', '11211', '11476',\n",
    "           '11477', '15068', '15573', '22885', '24201', '24246',\n",
    "           '25269', '29119', '29120', '33909', '35480', '36840',\n",
    "           '47458', '47905', '85984', '87079', '87087', '87580',\n",
    "           '93273', '98138', '99206']\n",
    "\n",
    "pred_fields = [\n",
    "    'YOLOv5',\n",
    "]\n",
    "\n",
    "# logging\n",
    "logs_dir = os.path.join('logs', dataset.name)\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "classification_metrics_summary_df = None\n",
    "for pred_field in pred_fields:\n",
    "    print(f'Processing {pred_field}')\n",
    "\n",
    "    # Only contains detections with confidence\n",
    "    high_conf_view = predictions_view.filter_labels(pred_field, F('confidence') > 0.60)\n",
    "\n",
    "    results = high_conf_view.evaluate_detections(\n",
    "        pred_field=pred_field,\n",
    "        gt_field='ground_truth',\n",
    "        eval_key=f'eval_{pred_field}',\n",
    "        compute_mAP=True,\n",
    "        classwise=False\n",
    "    )\n",
    "\n",
    "    classification_report_df = pd.DataFrame(results.report(classes)).transpose()\n",
    "    classification_report_df.to_csv(os.path.join(logs_dir, f'{pred_field}_classification_report.csv'))\n",
    "\n",
    "    classification_metrics_df = pd.DataFrame([results.metrics()], index=[pred_field])\n",
    "    classification_metrics_df['mAP'] = results.mAP()\n",
    "    classification_metrics_summary_df = classification_metrics_df if classification_metrics_summary_df is None else classification_metrics_summary_df.append(classification_metrics_df)\n",
    "\n",
    "    # save pr curve\n",
    "    pr_plot = results.plot_pr_curves(classes=classes, backend='matplotlib', figsize=(16,8))\n",
    "    pr_plot.savefig(f'{pred_field}_pr_curve.png', bbox_inches='tight')\n",
    "    # # plot pr curve\n",
    "    # plot = results.plot_pr_curves(classes=classes)\n",
    "    # plot._figure.write_json(os.path.join(logs_dir, f'{pred_field}_pr_curve.json'))\n",
    "    # plot._figure.write_html(os.path.join(logs_dir, f'{pred_field}_pr_curve.html'))\n",
    "    # # plot.show(height=720, width=720)\n",
    "\n",
    "    # save as matplotlib confusion matrix\n",
    "    # plot = results.plot_pr_curves(classes=classes, backend='matplotlib', figsize=(16,8))\n",
    "    # plot.savefig('pr_plot.png', bbox_inches='tight')\n",
    "    cm = results.confusion_matrix(classes=classes + [results.missing])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes + ['(NONE)'])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16,16))\n",
    "    disp.plot(ax=ax)\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "    fig.savefig(os.path.join(logs_dir, f'{pred_field}_confusion_matrix.png'), bbox_inches='tight')\n",
    "    # plt.show()\n",
    "\n",
    "    plot = results.plot_confusion_matrix(classes=classes)\n",
    "    plot._figure.write_json(os.path.join(logs_dir, f'{pred_field}_confusion_matrix.json'))\n",
    "    plot._figure.write_html(os.path.join(logs_dir, f'{pred_field}_confusion_matrix.html'))\n",
    "    # plot.show(height=720, width=720)\n",
    "\n",
    "classification_metrics_summary_df.to_csv(os.path.join(logs_dir, 'classification_metrics.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize View by Mistakenness Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# compute and add \"mistakenness\" score ranging between [-1, 1] (no mistakes, high mistakes)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfob\u001b[49m\u001b[38;5;241m.\u001b[39mcompute_mistakenness(\n\u001b[1;32m      3\u001b[0m     predictions_view, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYOLOv5\u001b[39m\u001b[38;5;124m'\u001b[39m, label_field\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mground_truth\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# set view to be based on mistakenness score\u001b[39;00m\n\u001b[1;32m      7\u001b[0m mistake_view \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39msort_by(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmistakenness\u001b[39m\u001b[38;5;124m'\u001b[39m, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fob' is not defined"
     ]
    }
   ],
   "source": [
    "# compute and add \"mistakenness\" score ranging between [-1, 1] (no mistakes, high mistakes)\n",
    "fob.compute_mistakenness(\n",
    "    predictions_view, 'YOLOv5', label_field='ground_truth', \n",
    ")\n",
    "\n",
    "# set view to be based on mistakenness score\n",
    "mistake_view = dataset.sort_by('mistakenness', reverse=True)\n",
    "session.view = mistake_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate visualization for `ground_truth` objects\n",
    "method = 'umap' #'umap' 'tsne' 'pca'\n",
    "vis_results = fob.compute_visualization(predictions_view, patches_field=\"ground_truth\", method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Generate scatterplot\n",
    "bbox_area = F('bounding_box')[2] * F('bounding_box')[3]\n",
    "plot = vis_results.visualize(\n",
    "    labels=F('ground_truth.detections.label'),\n",
    "    sizes=F('ground_truth.detections[]').apply(bbox_area),\n",
    ")\n",
    "plot.show(height=800)\n",
    "session.plots.attach(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
