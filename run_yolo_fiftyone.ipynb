{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Migrating database to v0.16.5\n"
     ]
    }
   ],
   "source": [
    "import os, io, glob\n",
    "from functools import partial\n",
    "\n",
    "import ffmpeg\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "from fiftyone import ViewField as F\n",
    "from fiftyone.utils import yolo\n",
    "import fiftyone.utils.annotations as foua\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Dataset and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'logs/weights/exp12.tgz' already exists. Skipping... Use 'force_download=True' to overwrite.\n",
      "'logs/dataset/dataset_1.tgz' already exists. Skipping... Use 'force_download=True' to overwrite.\n"
     ]
    }
   ],
   "source": [
    "import lego_utils\n",
    "\n",
    "dataset_url = \"https://s3.wasabisys.com/blender-rudy-set-background/dataset_1.tgz\"\n",
    "yolo_weights_url = \"https://github.com/LilDataMonster/Lego-CNN/releases/download/v0.0.3-yolo/exp12.tgz\"\n",
    "mrcnn_weights_url = \"https://github.com/LilDataMonster/Lego-CNN/releases/download/v0.0.3/mask_rcnn_lego_0200.h5\"\n",
    "\n",
    "base_asset_path = os.path.join(\"logs\")\n",
    "weights_path = os.path.join(base_asset_path, \"weights\")\n",
    "dataset_path = os.path.join(base_asset_path, \"dataset\")\n",
    "\n",
    "lego_utils.download_url(yolo_weights_url, weights_path, force_download=False)\n",
    "lego_utils.download_url(dataset_url, dataset_path, force_download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete all datasets from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_database = False\n",
    "\n",
    "if delete_database:\n",
    "    for ds in fo.list_datasets():\n",
    "        dataset = fo.load_dataset(ds)\n",
    "        dataset.delete()\n",
    "        print(f\"Removed from database: {ds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset dataset_1 - test...\n",
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2500/2500 [44.2s elapsed, 0s remaining, 53.8 samples/s]      \n",
      "Dataset: dataset_1 - test loaded\n",
      "Loading dataset dataset_1 - train...\n",
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2501/2501 [43.7s elapsed, 0s remaining, 60.1 samples/s]      \n",
      "Dataset: dataset_1 - train loaded\n"
     ]
    }
   ],
   "source": [
    "# loaded datasets\n",
    "datasets = []\n",
    "\n",
    "# load all coco datasets within the dataset_path\n",
    "for ds_subdir in os.listdir(dataset_path):\n",
    "    ds_fullpath = os.path.join(dataset_path, ds_subdir)\n",
    "    if os.path.isdir(ds_fullpath) and not ds_subdir.startswith(\".\"):\n",
    "        \n",
    "        # process by dataset splits\n",
    "        for ds_split in os.listdir(ds_fullpath):\n",
    "            ds_split_fullpath = os.path.join(ds_fullpath, ds_split)\n",
    "            \n",
    "            name = f\"{ds_subdir} - {ds_split}\"\n",
    "            \n",
    "            print(f\"Loading dataset {name}...\")\n",
    "            if name not in fo.list_datasets():\n",
    "                data_path = ds_split_fullpath\n",
    "                labels_path = os.path.join(data_path, \"coco_annotations.json\")\n",
    "                dataset_type = fo.types.COCODetectionDataset\n",
    "                \n",
    "                # load in dataset\n",
    "                dataset = fo.Dataset.from_dir(\n",
    "                    dataset_type=dataset_type,\n",
    "                    data_path=data_path,\n",
    "                    labels_path=labels_path,\n",
    "                    name=name\n",
    "                )\n",
    "                \n",
    "                # save dataset to database for persistence\n",
    "                dataset.persistent = True\n",
    "            else:\n",
    "                # dataset already save and persisted, load it from prior save\n",
    "                dataset = fo.load_dataset(name)\n",
    "            print(f\"Dataset: {name} loaded\")\n",
    "            datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    }
   ],
   "source": [
    "# visualize dataset in GUI\n",
    "session = fo.launch_app(port=5151, auto=False)#, remote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-6-26 Python-3.8.10 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11019MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-6-26 Python-3.8.10 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11019MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary: 290 layers, 21018615 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model summary: 290 layers, 21018615 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# download \n",
    "yolov5_model = torch.hub.load('ultralytics/yolov5', 'custom', path=os.path.join(weights_path, \"exp12\", \"weights\", \"best.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_detections = lambda row: fo.Detection(\n",
    "                        label=row['name'],\n",
    "                        bounding_box=[row['xcenter'] - row['width']/2, row['ycenter'] - row['height']/2,\n",
    "                                      row['width'], row['height']],\n",
    "                        confidence=row['confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c5121629c14ce0880fcce27f927595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished adding predictions\n"
     ]
    }
   ],
   "source": [
    "# Choose a random subset of 100 samples to add predictions to\n",
    "predictions_view = dataset.take(2500, seed=51)\n",
    "\n",
    "for sample in tqdm(predictions_view):\n",
    "    # Load image\n",
    "    image = Image.open(sample.filepath)\n",
    "    results = yolov5_model(image)\n",
    "    results_df = results.pandas().xywhn[0]\n",
    "    \n",
    "    detections = results_df.apply(create_detections, axis=1)\n",
    "    sample['YOLOv5'] = fo.Detections(detections=detections.values.tolist())\n",
    "    sample.save()\n",
    "\n",
    "print(\"Finished adding predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = predictions_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing YOLOv5\n",
      "Evaluating detections...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2500/2500 [3.3m elapsed, 0s remaining, 13.5 samples/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2500/2500 [3.3m elapsed, 0s remaining, 13.5 samples/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing IoU sweep...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing IoU sweep...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2500/2500 [3.1m elapsed, 0s remaining, 13.4 samples/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2500/2500 [3.1m elapsed, 0s remaining, 13.4 samples/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring unsupported argument `thresholds` for the 'matplotlib' backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring unsupported argument `thresholds` for the 'matplotlib' backend\n"
     ]
    }
   ],
   "source": [
    "classes = ['2431', '3003', '3005', '3010', '3020', '3021', '3022',\n",
    "           '3023', '3024', '3069', '3070', '3176', '3622', '3700',\n",
    "           '3710', '3958', '4150', '4274', '6141', '11211', '11476',\n",
    "           '11477', '15068', '15573', '22885', '24201', '24246',\n",
    "           '25269', '29119', '29120', '33909', '35480', '36840',\n",
    "           '47458', '47905', '85984', '87079', '87087', '87580',\n",
    "           '93273', '98138', '99206']\n",
    "\n",
    "pred_fields = [\n",
    "    'YOLOv5',\n",
    "]\n",
    "\n",
    "# logging\n",
    "logs_dir = os.path.join('logs', dataset.name)\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "classification_metrics_summary_df = None\n",
    "for pred_field in pred_fields:\n",
    "    print(f'Processing {pred_field}')\n",
    "\n",
    "    # Only contains detections with confidence\n",
    "    high_conf_view = predictions_view.filter_labels(pred_field, F('confidence') > 0.60)\n",
    "\n",
    "    results = high_conf_view.evaluate_detections(\n",
    "        pred_field=pred_field,\n",
    "        gt_field='ground_truth',\n",
    "        eval_key=f'eval_{pred_field}',\n",
    "        compute_mAP=True,\n",
    "        classwise=False\n",
    "    )\n",
    "\n",
    "    classification_report_df = pd.DataFrame(results.report(classes)).transpose()\n",
    "    classification_report_df.to_csv(os.path.join(logs_dir, f'{pred_field}_classification_report.csv'))\n",
    "\n",
    "    classification_metrics_df = pd.DataFrame([results.metrics()], index=[pred_field])\n",
    "    classification_metrics_df['mAP'] = results.mAP()\n",
    "    classification_metrics_summary_df = classification_metrics_df if classification_metrics_summary_df is None else classification_metrics_summary_df.append(classification_metrics_df)\n",
    "\n",
    "    # save pr curve\n",
    "    pr_plot = results.plot_pr_curves(classes=classes, backend='matplotlib', figsize=(16,8))\n",
    "    pr_plot.savefig(os.path.join(logs_dir, f'{pred_field}_pr_curve.png'), bbox_inches='tight')\n",
    "    # # plot pr curve\n",
    "    # plot = results.plot_pr_curves(classes=classes)\n",
    "    # plot._figure.write_json(os.path.join(logs_dir, f'{pred_field}_pr_curve.json'))\n",
    "    # plot._figure.write_html(os.path.join(logs_dir, f'{pred_field}_pr_curve.html'))\n",
    "    # # plot.show(height=720, width=720)\n",
    "\n",
    "    # save as matplotlib confusion matrix\n",
    "    # plot = results.plot_pr_curves(classes=classes, backend='matplotlib', figsize=(16,8))\n",
    "    # plot.savefig('pr_plot.png', bbox_inches='tight')\n",
    "    cm = results.confusion_matrix(classes=classes + [results.missing])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes + ['(NONE)'])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16,16))\n",
    "    disp.plot(ax=ax)\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "    fig.savefig(os.path.join(logs_dir, f'{pred_field}_confusion_matrix.png'), bbox_inches='tight')\n",
    "    # plt.show()\n",
    "\n",
    "    plot = results.plot_confusion_matrix(classes=classes)\n",
    "    plot._figure.write_json(os.path.join(logs_dir, f'{pred_field}_confusion_matrix.json'))\n",
    "    plot._figure.write_html(os.path.join(logs_dir, f'{pred_field}_confusion_matrix.html'))\n",
    "    # plot.show(height=720, width=720)\n",
    "\n",
    "classification_metrics_summary_df.to_csv(os.path.join(logs_dir, 'classification_metrics.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize View by Mistakenness Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2500/2500 [1.9m elapsed, 0s remaining, 23.5 samples/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2500/2500 [1.9m elapsed, 0s remaining, 23.5 samples/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing mistakenness...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing mistakenness...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2500/2500 [1.6m elapsed, 0s remaining, 28.5 samples/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2500/2500 [1.6m elapsed, 0s remaining, 28.5 samples/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistakenness computation complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mistakenness computation complete\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to post event `state_update` to http://localhost:5151/event",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# set view to be based on mistakenness score\u001b[39;00m\n\u001b[1;32m      7\u001b[0m mistake_view \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39msort_by(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmistakenness\u001b[39m\u001b[38;5;124m'\u001b[39m, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m session\u001b[38;5;241m.\u001b[39mview \u001b[38;5;241m=\u001b[39m mistake_view\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/fiftyone/core/session/session.py:212\u001b[0m, in \u001b[0;36mupdate_state.<locals>.decorator.<locals>.wrapper\u001b[0;34m(session, *args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m     session\u001b[38;5;241m.\u001b[39mfreeze()\n\u001b[1;32m    211\u001b[0m result \u001b[38;5;241m=\u001b[39m func(session, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 212\u001b[0m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mStateUpdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auto_show \u001b[38;5;129;01mand\u001b[39;00m session\u001b[38;5;241m.\u001b[39mauto \u001b[38;5;129;01mand\u001b[39;00m focx\u001b[38;5;241m.\u001b[39mis_notebook_context():\n\u001b[1;32m    214\u001b[0m     session\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/fiftyone/core/session/client.py:124\u001b[0m, in \u001b[0;36mClient.send_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connected:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClient is not connected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_event(event)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/fiftyone/core/session/client.py:168\u001b[0m, in \u001b[0;36mClient._post_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    157\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morigin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/event\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    159\u001b[0m     headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m     },\n\u001b[1;32m    165\u001b[0m )\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to post event `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent\u001b[38;5;241m.\u001b[39mget_event_name()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morigin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/event\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to post event `state_update` to http://localhost:5151/event"
     ]
    }
   ],
   "source": [
    "# compute and add \"mistakenness\" score ranging between [-1, 1] (no mistakes, high mistakes)\n",
    "fob.compute_mistakenness(\n",
    "    predictions_view, 'YOLOv5', label_field='ground_truth', \n",
    ")\n",
    "\n",
    "# set view to be based on mistakenness score\n",
    "mistake_view = dataset.sort_by('mistakenness', reverse=True)\n",
    "session.view = mistake_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing patch embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing patch embeddings...\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_1588_1083608515_0>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_1524_45833984_0>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "Traceback (most recent call last):\n",
      "RuntimeError: unable to write to file </torch_1332_1800607934_0>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "Traceback (most recent call last):\n",
      "RuntimeError: unable to write to file </torch_1620_213799112_24>: No space left on device (28)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "RuntimeError: unable to write to file </torch_1364_3697012844_0>: No space left on device (28)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_1492_3468850979_0>: No space left on device (28)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_1396_277406676_0>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "Traceback (most recent call last):\n",
      "RuntimeError: unable to write to file </torch_1300_609962245_0>: No space left on device (28)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_1780_1211278364_0>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_1460_2326039057_0>: No space left on device (28)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_1428_3274957433_0>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_1716_3750637623_0>: No space left on device (28)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "RuntimeError: unable to write to file </torch_1652_3608431157_0>: No space left on device (28)\n",
      "RuntimeError: unable to write to file </torch_1684_3248709388_0>: No space left on device (28)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_1748_3939410959_0>: No space left on device (28)\n",
      "ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_1588_1813622741_1>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_1492_2764687802_1>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_1332_348523926_1>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "RuntimeError: unable to write to file </torch_1460_599801290_1>: No space left on device (28)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "Traceback (most recent call last):\n",
      "RuntimeError: unable to write to file </torch_1716_2530216821_1>: No space left on device (28)\n",
      "RuntimeError: unable to write to file </torch_1364_2759767623_1>: No space left on device (28)\n",
      "RuntimeError: unable to write to file </torch_1524_736255332_1>: No space left on device (28)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_1780_3762054037_1>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_1300_846820177_1>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_1396_2945447535_1>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "RuntimeError: unable to write to file </torch_1748_2699698457_1>: No space left on device (28)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "RuntimeError: unable to write to file </torch_1428_1832324421_1>: No space left on device (28)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "Traceback (most recent call last):\n",
      "RuntimeError: unable to write to file </torch_1652_560244846_1>: No space left on device (28)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 239, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/reductions.py\", line 347, in reduce_storage\n",
      "    fd, size = storage._share_fd_()\n",
      "RuntimeError: unable to write to file </torch_1684_1630716114_1>: No space left on device (28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -0% ||--------------|   -1/2500 [4.4s elapsed, ? remaining, ? samples/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -0% ||--------------|   -1/2500 [4.4s elapsed, ? remaining, ? samples/s] \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 1556) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m/usr/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 1556) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate visualization for `ground_truth` objects\u001b[39;00m\n\u001b[1;32m      2\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mumap\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#'umap' 'tsne' 'pca'\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m vis_results \u001b[38;5;241m=\u001b[39m \u001b[43mfob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_visualization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions_view\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatches_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mground_truth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/fiftyone/brain/__init__.py:347\u001b[0m, in \u001b[0;36mcompute_visualization\u001b[0;34m(samples, patches_field, embeddings, points, brain_key, num_dims, method, model, force_square, alpha, batch_size, num_workers, skip_failures, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03m\"\"\"Computes a low-dimensional representation of the samples' media or their\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03mpatches that can be interactively visualized.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m    a :class:`fiftyone.brain.visualization.VisualizationResults`\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfiftyone\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mfbv\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_visualization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatches_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbrain_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_square\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_failures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/fiftyone/brain/internal/core/visualization.py:93\u001b[0m, in \u001b[0;36mcompute_visualization\u001b[0;34m(samples, patches_field, embeddings, points, brain_key, num_dims, method, model, force_square, alpha, batch_size, num_workers, skip_failures, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     brain_method\u001b[38;5;241m.\u001b[39mregister_run(samples, brain_key)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m points \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mfbu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatches_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatches_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_square\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_square\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_failures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_failures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating visualization...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m     points \u001b[38;5;241m=\u001b[39m brain_method\u001b[38;5;241m.\u001b[39mfit(embeddings)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/fiftyone/brain/internal/core/utils.py:126\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(samples, model, patches_field, embeddings_field, embeddings, force_square, alpha, handle_missing, agg_fcn, batch_size, num_workers, skip_failures)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m patches_field \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing patch embeddings...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 126\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43msamples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_patch_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatches_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_square\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_square\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhandle_missing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_failures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_failures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing embeddings...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/fiftyone/core/collections.py:1894\u001b[0m, in \u001b[0;36mSampleCollection.compute_patch_embeddings\u001b[0;34m(self, model, patches_field, embeddings_field, force_square, alpha, handle_missing, batch_size, num_workers, skip_failures)\u001b[0m\n\u001b[1;32m   1812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_patch_embeddings\u001b[39m(\n\u001b[1;32m   1813\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1814\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1822\u001b[0m     skip_failures\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1823\u001b[0m ):\n\u001b[1;32m   1824\u001b[0m     \u001b[38;5;124;03m\"\"\"Computes embeddings for the image patches defined by\u001b[39;00m\n\u001b[1;32m   1825\u001b[0m \u001b[38;5;124;03m    ``patches_field`` of the samples in the collection using the given\u001b[39;00m\n\u001b[1;32m   1826\u001b[0m \u001b[38;5;124;03m    :class:`fiftyone.core.models.Model`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1892\u001b[0m \u001b[38;5;124;03m            embeddings\u001b[39;00m\n\u001b[1;32m   1893\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfomo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_patch_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1895\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1896\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatches_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1898\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_square\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_square\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhandle_missing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_failures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_failures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1905\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/fiftyone/core/models.py:1144\u001b[0m, in \u001b[0;36mcompute_patch_embeddings\u001b[0;34m(samples, model, patches_field, embeddings_field, force_square, alpha, handle_missing, batch_size, num_workers, skip_failures)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _embed_frame_patches(\n\u001b[1;32m   1132\u001b[0m         samples,\n\u001b[1;32m   1133\u001b[0m         model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         skip_failures,\n\u001b[1;32m   1141\u001b[0m     )\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_data_loader:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_embed_patches_data_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatches_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_square\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle_missing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_failures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _embed_patches(\n\u001b[1;32m   1158\u001b[0m     samples,\n\u001b[1;32m   1159\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     skip_failures,\n\u001b[1;32m   1167\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/fiftyone/core/models.py:1285\u001b[0m, in \u001b[0;36m_embed_patches_data_loader\u001b[0;34m(samples, model, patches_field, embeddings_field, force_square, alpha, handle_missing, batch_size, num_workers, skip_failures)\u001b[0m\n\u001b[1;32m   1282\u001b[0m embeddings_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fou\u001b[38;5;241m.\u001b[39mProgressBar(samples) \u001b[38;5;28;01mas\u001b[39;00m pb:\n\u001b[0;32m-> 1285\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sample, patches \u001b[38;5;129;01min\u001b[39;00m pb(\u001b[38;5;28mzip\u001b[39m(samples, data_loader)):\n\u001b[1;32m   1286\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/eta/core/utils.py:1660\u001b[0m, in \u001b[0;36mProgressBar.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1660\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1661\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1662\u001b[0m         \u001b[38;5;66;03m# Update once more so progress reaches 100%\u001b[39;00m\n\u001b[1;32m   1663\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(draw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1207\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:1173\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1173\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1175\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:1024\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1023\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pids_str)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 1556) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# Generate visualization for `ground_truth` objects\n",
    "method = 'umap' #'umap' 'tsne' 'pca'\n",
    "vis_results = fob.compute_visualization(predictions_view, patches_field=\"ground_truth\", method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Generate scatterplot\n",
    "bbox_area = F('bounding_box')[2] * F('bounding_box')[3]\n",
    "plot = vis_results.visualize(\n",
    "    labels=F('ground_truth.detections.label'),\n",
    "    sizes=F('ground_truth.detections[]').apply(bbox_area),\n",
    ")\n",
    "plot.show(height=800)\n",
    "session.plots.attach(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
