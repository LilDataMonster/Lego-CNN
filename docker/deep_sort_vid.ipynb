{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "# import ffmpeg\n",
    "\n",
    "from mrcnn import visualize\n",
    "import mrcnn.model as modellib\n",
    "\n",
    "import lego\n",
    "\n",
    "from deep_sort import preprocessing\n",
    "from deep_sort import nn_matching\n",
    "from deep_sort.detection import Detection\n",
    "from deep_sort.tracker import Tracker\n",
    "from deep_sort import generate_detections\n",
    "\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: [128, 64, 3]\n"
     ]
    }
   ],
   "source": [
    "model_feature = 'mars-small128.pb'\n",
    "# model_feature = 'market1501.pb'\n",
    "min_score = 0.7\n",
    "\n",
    "encoder = generate_detections.create_box_encoder(model_feature, batch_size=1)\n",
    "metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", min_score, None)\n",
    "tracker = Tracker(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def render_detections(image, boxes, masks, class_ids, scores, class_names, image_name=None, filter_classs_names=None,\n",
    "               scores_thresh=0.1, save_dir=None, mode=0):\n",
    "    \"\"\"\n",
    "        image: image array\n",
    "        image_name: image name\n",
    "        boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
    "        masks: [num_instances, height, width]\n",
    "        class_ids: [num_instances]\n",
    "        scores: confidence scores for each box\n",
    "        class_names: list of class names of the dataset\n",
    "        filter_classs_names: (optional) list of class names we want to draw\n",
    "        scores_thresh: (optional) threshold of confidence scores\n",
    "        save_dir: (optional) the path to store image\n",
    "        mode: (optional) select the result which you want\n",
    "                mode = 0 , save image with bbox,class_name,score and mask;\n",
    "                mode = 1 , save image with bbox,class_name and score;\n",
    "                mode = 2 , save image with class_name,score and mask;\n",
    "                mode = 3 , save mask with black background;\n",
    "    \"\"\"\n",
    "    mode_list = [0, 1, 2, 3]\n",
    "    assert mode in mode_list, \"mode's value should in mode_list %s\" % str(mode_list)\n",
    "\n",
    "    if save_dir is None and image_name is not None:\n",
    "        save_dir = os.path.join(os.getcwd(), \"output\")\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "    useful_mask_indices = []\n",
    "\n",
    "    N = boxes.shape[0]\n",
    "    if not N:\n",
    "        print(\"\\n*** No instances in image %s to draw *** \\n\" % (image_name))\n",
    "        return\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
    "\n",
    "    for i in range(N):\n",
    "        # filter\n",
    "        class_id = class_ids[i]\n",
    "        score = scores[i] if scores is not None else None\n",
    "        if score is None or score < scores_thresh:\n",
    "            continue\n",
    "\n",
    "        label = class_names[class_id]\n",
    "        if (filter_classs_names is not None) and (label not in filter_classs_names):\n",
    "            continue\n",
    "\n",
    "        if not np.any(boxes[i]):\n",
    "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
    "            continue\n",
    "\n",
    "        useful_mask_indices.append(i)\n",
    "\n",
    "    if len(useful_mask_indices) == 0:\n",
    "        print(\"\\n*** No instances in image %s to draw *** \\n\" % (image_name))\n",
    "        return\n",
    "\n",
    "    colors = visualize.random_colors(len(useful_mask_indices))\n",
    "\n",
    "    if mode != 3:\n",
    "        masked_image = image.astype(np.uint8).copy()\n",
    "    else:\n",
    "        masked_image = np.zeros(image.shape).astype(np.uint8)\n",
    "\n",
    "    if mode != 1:\n",
    "        for index, value in enumerate(useful_mask_indices):\n",
    "            masked_image = visualize.apply_mask(masked_image, masks[:, :, value], colors[index])\n",
    "\n",
    "    masked_image = Image.fromarray(masked_image)\n",
    "\n",
    "    if mode == 3:\n",
    "        if image_name is not None:\n",
    "            masked_image.save(os.path.join(save_dir, '%s.jpg' % (image_name)))\n",
    "        return masked_image\n",
    "\n",
    "    draw = ImageDraw.Draw(masked_image)\n",
    "    colors = np.array(colors).astype(int) * 255\n",
    "\n",
    "    for index, value in enumerate(useful_mask_indices):\n",
    "        class_id = class_ids[value]\n",
    "        score = scores[value]\n",
    "        label = class_names[class_id]\n",
    "\n",
    "        y1, x1, y2, x2 = boxes[value]\n",
    "        if mode != 2:\n",
    "            color = tuple(colors[index])\n",
    "            draw.rectangle((x1, y1, x2, y2), outline=color)\n",
    "\n",
    "        # Label\n",
    "        # font = ImageFont.truetype('/Library/Fonts/Arial.ttf', 15)\n",
    "        # draw.text((x1, y1), \"%s %f\" % (label, score), (255, 255, 255), font)\n",
    "        draw.text((x1, y1), \"%s %f\" % (label, score), (255, 255, 255))\n",
    "\n",
    "    if image_name is not None:\n",
    "        masked_image.save(os.path.join(save_dir, '%s.jpg' % (image_name)))\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_URL = 'https://api.github.com/repos/LilDataMonster/Lego-CNN/releases/latest'\n",
    "response = json.loads(requests.get(REPO_URL).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0.00/262M [00:00<?, ?iB/s]\n"
     ]
    }
   ],
   "source": [
    "LEGO_WEIGHTS_URL = response['assets'][0]['browser_download_url']\n",
    "LEGO_WEIGHTS_NAME = os.path.basename(LEGO_WEIGHTS_URL)\n",
    "\n",
    "LEGO_WEIGHTS_PATH = Path(os.path.join('.', LEGO_WEIGHTS_NAME))\n",
    "\n",
    "weights_response = requests.get(LEGO_WEIGHTS_URL, stream=True)\n",
    "total_size_in_bytes= int(weights_response.headers.get('content-length', 0))\n",
    "progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
    "if not LEGO_WEIGHTS_PATH.exists():\n",
    "    # Streaming, so we can iterate over the response.\n",
    "    block_size = 1024 #1 Kibibyte\n",
    "    with open(LEGO_WEIGHTS_NAME, 'wb') as file:\n",
    "        for data in weights_response.iter_content(block_size):\n",
    "            progress_bar.update(len(data))\n",
    "            file.write(data)\n",
    "\n",
    "    if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
    "        print(\"ERROR downloading pretrained weights\")\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(lego.LegoConfig().__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "Loading weights  mask_rcnn_lego_0200.h5\n"
     ]
    }
   ],
   "source": [
    "# # Directory to save logs and trained model\n",
    "# MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "# LEGO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"snapshots\", \"weights\",\"mask_rcnn_lego_0111.h5\") # Comment out to use snapshot from latest training\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=\"\", config=config)\n",
    "print(\"Loading weights \", LEGO_WEIGHTS_PATH)\n",
    "model.load_weights(LEGO_WEIGHTS_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = lego.LegoDataset()\n",
    "# dataset.prepare()\n",
    "#dataset.class_names\n",
    "class_names = ['BG', '2431', '3003', '3005', '3010', '3020', '3021', '3022', '3023', '3024', '3069', '3070', '3176', '3622', '3700', '3710', '3958', '4150', '4274', '6141', '11211', '11476', '11477', '15068', '15573', '22885', '24201', '24246', '25269', '29119', '29120', '33909', '35480', '36840', '47458', '47905', '85984', '87079', '87087', '87580', '93273', '98138', '99206']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from cv2 import CAP_PROP_FRAME_COUNT\n",
    "\n",
    "def frame_iter(capture, description):\n",
    "    def _iterator():\n",
    "        while capture.grab():\n",
    "            yield capture.retrieve()[1]\n",
    "    return tqdm(\n",
    "        _iterator(),\n",
    "        desc=description,\n",
    "        total=int(capture.get(CAP_PROP_FRAME_COUNT)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import random\n",
    "def draw_bbox(image, bboxes, CLASSES=class_names, show_label=True, show_confidence = True, Text_colors=(255,255,0), rectangle_colors='', tracking=False):   \n",
    "#     NUM_CLASS = read_class_names(CLASSES)\n",
    "    NUM_CLASS = class_names\n",
    "    num_classes = len(class_names)\n",
    "    image_h, image_w, _ = image.shape\n",
    "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "    #print(\"hsv_tuples\", hsv_tuples)\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "\n",
    "    random.seed(0)\n",
    "    random.shuffle(colors)\n",
    "    random.seed(None)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "#         coor = np.array(bbox[:4], dtype=np.int32)\n",
    "        score = bbox[4]\n",
    "        class_ind = int(bbox[5])\n",
    "        bbox_color = rectangle_colors if rectangle_colors != '' else colors[class_ind]\n",
    "        bbox_thick = int(0.6 * (image_h + image_w) / 1000)\n",
    "        if bbox_thick < 1: bbox_thick = 1\n",
    "        fontScale = 0.75 * bbox_thick\n",
    "#         (x1, y1), (x2, y2) = (coor[0], coor[1]), (coor[2], coor[3])\n",
    "        y1, x1, y2, x2 = np.array(bbox[:4], dtype=np.int32)\n",
    "\n",
    "        # put object rectangle\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), bbox_color, bbox_thick*2)\n",
    "#         cv2.rectangle(image, (x1, y1), ((x2 - x1), (y2 - y1)), bbox_color, bbox_thick*2)\n",
    "\n",
    "        if show_label:\n",
    "            # get text label\n",
    "            score_str = \" {:.2f}\".format(score) if show_confidence else \"\"\n",
    "\n",
    "            if tracking: score_str = \" \"+str(score)\n",
    "\n",
    "            label = \"{}\".format(NUM_CLASS[class_ind]) + score_str\n",
    "\n",
    "            # get text size\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                                                                  fontScale, thickness=bbox_thick)\n",
    "            # put filled text rectangle\n",
    "            cv2.rectangle(image, (x1, y1), (x1 + text_width, y1 - text_height - baseline), bbox_color, thickness=cv2.FILLED)\n",
    "\n",
    "            # put text above rectangle\n",
    "            cv2.putText(image, label, (x1, y1-4), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                        fontScale, Text_colors, bbox_thick, lineType=cv2.LINE_AA)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = visualize.random_colors(len(class_names))\n",
    "colors = (np.array(colors).astype(float) * 255).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detect_movie.mp4:   0%|          | 0/1050 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2424: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
      "detect_movie.mp4: 100%|██████████| 1050/1050 [08:17<00:00,  2.11it/s]\n"
     ]
    }
   ],
   "source": [
    "video_filename = 'movie.mp4'\n",
    "cap = cv2.VideoCapture(video_filename)\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "detect_video_filename = 'detect_' + video_filename\n",
    "out = cv2.VideoWriter(detect_video_filename, cv2.VideoWriter_fourcc('M','J','P','G'), 60, (frame_width,frame_height))\n",
    "\n",
    "track_total = []\n",
    "for frame in frame_iter(cap, detect_video_filename):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = model.detect([frame], verbose=0)[0]\n",
    "    \n",
    "    boxes = results['rois']\n",
    "    masks = results['masks']\n",
    "    class_ids = results['class_ids']\n",
    "    classes_scores = results['scores']\n",
    "\n",
    "    N = boxes.shape[0]\n",
    "    return_boxes = []\n",
    "    return_scores = []\n",
    "    return_masks = []\n",
    "    return_class_names = []\n",
    "    return_class_color = []\n",
    "\n",
    "    for i in range(N):\n",
    "        class_id = class_ids[i]\n",
    "        classes_score = classes_scores[i]\n",
    "\n",
    "        if classes_score < min_score: continue\n",
    "\n",
    "        return_scores.append(classes_score)\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        return_boxes.append([x1, y1, (x2 - x1), (y2 - y1)])\n",
    "        return_masks.append(masks[:, :, i])\n",
    "        return_class_names.append(class_names[class_id])\n",
    "        return_class_color.append(colors[i])\n",
    "        \n",
    "    results['class_colors'] = [colors[cid] for cid in results['class_ids']]\n",
    "\n",
    "    features = encoder(frame, return_boxes)\n",
    "    \n",
    "    detections = []\n",
    "    for bbox, score, classes, mask, color, feature in zip(results['rois'], results['scores'], results['class_ids'], results['masks'], results['class_colors'], features):\n",
    "        detections.append(Detection(bbox, score, classes, mask, color, feature))\n",
    "\n",
    "#     boxes = np.array([d.tlwh for d in detections])\n",
    "#     scores = np.array([d.confidence for d in detections])\n",
    "#     indices = preprocessing.non_max_suppression(boxes, 1.0, scores)\n",
    "#     detections = [detections[i] for i in indices]\n",
    "        \n",
    "    # Pass detections to the deepsort object and obtain the track information.\n",
    "    tracker.predict()\n",
    "    tracker.update(detections)\n",
    "    \n",
    "    # Obtain info from the tracks\n",
    "    track_count = 0\n",
    "    tracked_bboxes = []\n",
    "    for track in tracker.tracks:\n",
    "        if not track.is_confirmed() or track.time_since_update > 5:\n",
    "            continue \n",
    "#         bbox = track.to_tlbr() # Get the corrected/predicted bounding box\n",
    "        bbox = track.to_tlwh()\n",
    "        class_name = track.get_class() # Get the class name of particular object\n",
    "        tracking_id = track.track_id # Get the ID for the particular track\n",
    "        \n",
    "        track_total.append(tracking_id)\n",
    "        track_count += 1\n",
    "        \n",
    "#         index = key_list[val_list.index(class_name)] # Get predicted object index by object name\n",
    "#         tracked_bboxes.append(bbox.tolist() + [tracking_id, index]) # Structure data, that we could use it with our draw_bbox function\n",
    "\n",
    "#         index = class_names.index(class_name)\n",
    "        index = class_name\n",
    "        tracked_bboxes.append(bbox.tolist() + [tracking_id, index]) # Structure data, that we could use it with our draw_bbox function\n",
    "        \n",
    "    # draw detection on frame\n",
    "    frame_detect = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    image = draw_bbox(frame_detect, tracked_bboxes, tracking=True)\n",
    "    \n",
    "#     output_image = render_detections(frame, results['rois'], results['masks'], results['class_ids'], results['scores'], class_names, filter_classs_names=None, scores_thresh=0.1, save_dir=None, mode=0)\n",
    "    \n",
    "#     plt_image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "#     plt.figure(figsize=(24,16))\n",
    "#     plt.subplot(121)\n",
    "#     plt.imshow(plt_image)\n",
    "#     plt.subplot(122)\n",
    "#     plt.imshow(output_image)\n",
    "#     plt.show()\n",
    "    \n",
    "#     print(bbox)\n",
    "    \n",
    "#     break\n",
    "    \n",
    "# #     frame_detect = render_detections(frame, results['rois'], results['masks'], results['class_ids'], results['scores'], class_names, filter_classs_names=None, scores_thresh=0.1, save_dir=None, mode=0)\n",
    "# #     frame_detect = np.array(frame_detect)\n",
    "    \n",
    "# #     frame_detect = cv2.cvtColor(frame_detect, cv2.COLOR_RGB2BGR)\n",
    "    out.write(image)\n",
    "    \n",
    "cap.release()    \n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bbox\n",
    "bbox = [1067, 311, 213, 254]\n",
    "tmp_frame = frame.copy()\n",
    "for bbox in results['rois']:\n",
    "    coor = np.array(bbox[:4], dtype=np.int32)\n",
    "#     (x1, y1), (x2, y2) = (coor[0], coor[1]), (coor[2], coor[3])\n",
    "    (y1, x1), (y2, x2) = (coor[0], coor[1]), (coor[2], coor[3])\n",
    "    cv2.rectangle(tmp_frame, (x1, y1), (x2, y2), [255, 0, 0], 2)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(tmp_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_frame = frame.copy()\n",
    "for det in detections:\n",
    "#     y1, x1, y2, x2 = np.array(det.to_tlbr(), dtype=np.int32)\n",
    "    y1, x1, y2, x2 = np.array(det.tlwh, dtype=np.int32)\n",
    "    \n",
    "    cv2.rectangle(tmp_frame, (x1, y1), (x2, y2), [255, 0, 0], 2)\n",
    "#     cv2.rectangle(tmp_frame, (x1, y1), ((x2 - x1), (y2 - y1)), [255, 0, 0], 2)\n",
    "    \n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(tmp_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_frame = frame.copy()\n",
    "for bbox in tracked_bboxes:\n",
    "#     y1, x1, y2, x2 = np.array(det.to_tlbr(), dtype=np.int32)\n",
    "    y1, x1, y2, x2 = np.array(bbox[:4], dtype=np.int32)\n",
    "    cv2.rectangle(tmp_frame, (x1, y1), (x2, y2), [255, 0, 0], 2)\n",
    "    \n",
    "#     cv2.rectangle(tmp_frame, (x1, y1), ((x2 - x1), (y2 - y1)), [255, 0, 0], 2)\n",
    "    \n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(tmp_frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
